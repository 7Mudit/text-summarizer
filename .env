VITE_RAPID_API_ARTICLE_KEY= 09889df77fmshaf54c45cc65688ep1aac89jsnc4d86513c49b 

const axios = require('axios');

const options = {
  method: 'POST',
  url: 'https://article-extractor-and-summarizer.p.rapidapi.com/summarize-text',
  headers: {
    'content-type': 'application/json',
    'X-RapidAPI-Key': '09889df77fmshaf54c45cc65688ep1aac89jsnc4d86513c49b',
    'X-RapidAPI-Host': 'article-extractor-and-summarizer.p.rapidapi.com'
  },
  data: {
    text: '##The problem\nLet\'s ask ChatGPT to summarize a fresh piece of news:\n\n\nGPT hallucinates. But it is not apparent.\nThis looks pretty legitimate, isn\'t it? GPT gives a summary for existing links and detects broken links, which apparently means there is a web scraper underneath, woah!\n\nOf course not. GPT is just smart.\n\nThe biggest issue here is that it is not even obvious for the user that this is a pure fantasy of GPT, so I was pretty sure GPT is able to get the new content from the web until I have started doing real and thorough fact checking of the summary it produced.\n\nTLDR: if you feed the URL of a random article into GPT, and ask it to summarize, using "please summarize <url>" prompt, it hallucinates by just analyzing words in the URL â€“ it does NOT get the actual content of an article (Ok, this is true for the end of March of 2023, I am pretty sure this might change soon with OpenAI plugins).\n\nAs you can see on this screenshot above, GPT not only hallucinates, it is also smart enough to gaslight the user when the user tries to check how it behaves on a non-existing URL! GPT leverages context knowledge from the chat to understand that the second URL is looking bad.\n\nBut how do I know?'
  }
};

try {
	const response = await axios.request(options);
	console.log(response.data);
} catch (error) {
	console.error(error);
}